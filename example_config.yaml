# How may cloud workers do we have in total.
num_cloud_workers: 10

# How long do we run the simulation.
time_to_run: 1000

# Latency between client and frontend server.
client_frontend_latency: 0.1

# Latency between frontend server and cloud worker.
frontend_worker_latency: 0.002

# Latency for database IO.
database_io_latency: 0.005

# Latency to run speech inference engine.
worker_inference_latency: 0.5

# Flops cost to run one inference.
flops_per_inference: 1000000

# How often do we send requests.
client_request_interval: 10

# Mean time of a model version update for each worker.
worker_update_mean_time: 3600
